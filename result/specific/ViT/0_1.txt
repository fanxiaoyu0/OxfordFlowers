[38;5;2m[i 0509 19:47:21.482677 88 compiler.py:951] Jittor(1.3.3.14) src: /home/prs01/miniconda3/envs/jittor/lib/python3.7/site-packages/jittor[m
[38;5;2m[i 0509 19:47:21.498063 88 compiler.py:952] g++ at /usr/bin/g++(9.4.0)[m
[38;5;2m[i 0509 19:47:21.498247 88 compiler.py:953] cache_path: /home/prs01/.cache/jittor/jt1.3.3/g++9.4.0/py3.7.13/Linux-5.4.0-10xc4/IntelRXeonRGolx7a/default[m
[38;5;2m[i 0509 19:47:21.544157 88 install_cuda.py:53] cuda_driver_version: [11, 6][m
[38;5;2m[i 0509 19:47:21.558547 88 __init__.py:411] Found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/bin/nvcc(11.2.152) at /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/bin/nvcc.[m
[38;5;2m[i 0509 19:47:21.574613 88 __init__.py:411] Found addr2line(2.34) at /usr/bin/addr2line.[m
[38;5;2m[i 0509 19:47:21.803590 88 compiler.py:1006] cuda key:cu11.2.152_sm_86[m
[38;5;2m[i 0509 19:47:22.111306 88 __init__.py:227] Total mem: 251.56GB, using 16 procs for compiling.[m
[38;5;2m[i 0509 19:47:22.242047 88 jit_compiler.cc:28] Load cc_path: /usr/bin/g++[m
[38;5;2m[i 0509 19:47:22.393504 88 init.cc:62] Found cuda archs: [86,][m
[38;5;2m[i 0509 19:47:22.687000 88 compile_extern.py:516] mpicc not found, distribution disabled.[m
[38;5;2m[i 0509 19:47:22.775141 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/cublas.h[m
[38;5;2m[i 0509 19:47:22.804988 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcublas.so[m
[38;5;2m[i 0509 19:47:22.805274 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcublasLt.so.11[m
[38;5;2m[i 0509 19:47:23.458599 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/cudnn.h[m
[38;5;2m[i 0509 19:47:23.512425 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn.so.8[m
[38;5;2m[i 0509 19:47:23.512567 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_ops_infer.so.8[m
[38;5;2m[i 0509 19:47:23.534552 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_ops_train.so.8[m
[38;5;2m[i 0509 19:47:23.538450 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_cnn_infer.so.8[m
[38;5;2m[i 0509 19:47:23.577201 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_cnn_train.so.8[m
[38;5;2m[i 0509 19:47:24.194687 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/curand.h[m
[38;5;2m[i 0509 19:47:24.267832 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcurand.so[m
[38;5;2m[i 0509 19:47:24.291548 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/cufft.h[m
[38;5;2m[i 0509 19:47:24.359161 88 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcufft.so[m
[38;5;2m[i 0509 19:47:24.496539 88 cuda_flags.cc:32] CUDA enabled.[m
Loading data...
[38;5;2m[i 0509 19:47:24.557609 88 dataset.py:631] Found 102 classes and 1020 images.[m
[38;5;2m[i 0509 19:47:24.584336 88 dataset.py:631] Found 102 classes and 1020 images.[m
----------------- A new trial ---------------------
modelName ViT learning rate: 5e-05 etaMin 1e-05 imgSize 224 savedName 0_1.pkl criterion CrossEntropyLoss weight_decay 0.001 TMax 15
Training:   0%|          | 0/200 [00:00<?, ?it/s][38;5;3m[w 0509 19:47:24.731435 88 grad.cc:77] grads[0] 'cls_token' doesn't have gradient. It will be set to zero: Var(1294:1:2:2:i1:o1:s0:n1,float32,cls_token,0)[1,1,768,][m
[38;5;3m[w 0509 19:47:24.731471 88 grad.cc:77] grads[1] 'pos_embed' doesn't have gradient. It will be set to zero: Var(1247:1:2:2:i1:o1:s0:n1,float32,pos_embed,0)[1,197,768,][m
[38;5;3m[w 0509 19:47:24.731478 88 grad.cc:77] grads[2] 'patch_embed.proj.weight' doesn't have gradient. It will be set to zero: Var(15:1:2:2:i1:o1:s0:n1,float32,patch_embed.proj.weight,0)[768,3,16,16,][m
[38;5;3m[w 0509 19:47:24.731487 88 grad.cc:77] grads[3] 'patch_embed.proj.bias' doesn't have gradient. It will be set to zero: Var(32:1:2:2:i1:o1:s0:n1,float32,patch_embed.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731492 88 grad.cc:77] grads[4] 'blocks.0.norm1.weight' doesn't have gradient. It will be set to zero: Var(1308:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.731497 88 grad.cc:77] grads[5] 'blocks.0.norm1.bias' doesn't have gradient. It will be set to zero: Var(1303:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731502 88 grad.cc:77] grads[6] 'blocks.0.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(1352:1:2:2:i1:o1:s0:n1,float32,blocks.0.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.731507 88 grad.cc:77] grads[7] 'blocks.0.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(1399:1:2:2:i1:o1:s0:n1,float32,blocks.0.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.731512 88 grad.cc:77] grads[8] 'blocks.0.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(1408:1:2:2:i1:o1:s0:n1,float32,blocks.0.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731516 88 grad.cc:77] grads[9] 'blocks.0.norm2.weight' doesn't have gradient. It will be set to zero: Var(1419:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.731521 88 grad.cc:77] grads[10] 'blocks.0.norm2.bias' doesn't have gradient. It will be set to zero: Var(1414:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731525 88 grad.cc:77] grads[11] 'blocks.0.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(1463:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.731530 88 grad.cc:77] grads[12] 'blocks.0.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(1472:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.731535 88 grad.cc:77] grads[13] 'blocks.0.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(1516:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.731540 88 grad.cc:77] grads[14] 'blocks.0.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(1525:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731545 88 grad.cc:77] grads[15] 'blocks.1.norm1.weight' doesn't have gradient. It will be set to zero: Var(1536:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.731549 88 grad.cc:77] grads[16] 'blocks.1.norm1.bias' doesn't have gradient. It will be set to zero: Var(1531:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731554 88 grad.cc:77] grads[17] 'blocks.1.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(1580:1:2:2:i1:o1:s0:n1,float32,blocks.1.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.731559 88 grad.cc:77] grads[18] 'blocks.1.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(1627:1:2:2:i1:o1:s0:n1,float32,blocks.1.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.731565 88 grad.cc:77] grads[19] 'blocks.1.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(1636:1:2:2:i1:o1:s0:n1,float32,blocks.1.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.731571 88 grad.cc:77] grads[20] 'blocks.1.norm2.weight' doesn't have gradient. It will be set to zero: Var(1647:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.731578 88 grad.cc:77] grads[21] 'blocks.1.norm2.bias' doesn't have gradient. It will be set to zero: Var(1642:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741792 88 grad.cc:77] grads[22] 'blocks.1.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(1691:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741801 88 grad.cc:77] grads[23] 'blocks.1.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(1700:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.741807 88 grad.cc:77] grads[24] 'blocks.1.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(1744:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.741813 88 grad.cc:77] grads[25] 'blocks.1.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(1753:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741818 88 grad.cc:77] grads[26] 'blocks.2.norm1.weight' doesn't have gradient. It will be set to zero: Var(1764:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.741824 88 grad.cc:77] grads[27] 'blocks.2.norm1.bias' doesn't have gradient. It will be set to zero: Var(1759:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741829 88 grad.cc:77] grads[28] 'blocks.2.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(1808:1:2:2:i1:o1:s0:n1,float32,blocks.2.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741837 88 grad.cc:77] grads[29] 'blocks.2.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(1855:1:2:2:i1:o1:s0:n1,float32,blocks.2.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.741842 88 grad.cc:77] grads[30] 'blocks.2.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(1864:1:2:2:i1:o1:s0:n1,float32,blocks.2.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741847 88 grad.cc:77] grads[31] 'blocks.2.norm2.weight' doesn't have gradient. It will be set to zero: Var(1875:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.741853 88 grad.cc:77] grads[32] 'blocks.2.norm2.bias' doesn't have gradient. It will be set to zero: Var(1870:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741858 88 grad.cc:77] grads[33] 'blocks.2.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(1919:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741864 88 grad.cc:77] grads[34] 'blocks.2.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(1928:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.741869 88 grad.cc:77] grads[35] 'blocks.2.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(1972:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.741874 88 grad.cc:77] grads[36] 'blocks.2.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(1981:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741879 88 grad.cc:77] grads[37] 'blocks.3.norm1.weight' doesn't have gradient. It will be set to zero: Var(1992:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.741884 88 grad.cc:77] grads[38] 'blocks.3.norm1.bias' doesn't have gradient. It will be set to zero: Var(1987:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741889 88 grad.cc:77] grads[39] 'blocks.3.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2036:1:2:2:i1:o1:s0:n1,float32,blocks.3.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741895 88 grad.cc:77] grads[40] 'blocks.3.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2083:1:2:2:i1:o1:s0:n1,float32,blocks.3.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.741901 88 grad.cc:77] grads[41] 'blocks.3.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2092:1:2:2:i1:o1:s0:n1,float32,blocks.3.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741906 88 grad.cc:77] grads[42] 'blocks.3.norm2.weight' doesn't have gradient. It will be set to zero: Var(2103:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.741912 88 grad.cc:77] grads[43] 'blocks.3.norm2.bias' doesn't have gradient. It will be set to zero: Var(2098:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741919 88 grad.cc:77] grads[44] 'blocks.3.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2147:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741924 88 grad.cc:77] grads[45] 'blocks.3.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2156:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.741930 88 grad.cc:77] grads[46] 'blocks.3.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2200:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.741936 88 grad.cc:77] grads[47] 'blocks.3.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2209:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741941 88 grad.cc:77] grads[48] 'blocks.4.norm1.weight' doesn't have gradient. It will be set to zero: Var(2220:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.741947 88 grad.cc:77] grads[49] 'blocks.4.norm1.bias' doesn't have gradient. It will be set to zero: Var(2215:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741952 88 grad.cc:77] grads[50] 'blocks.4.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2264:1:2:2:i1:o1:s0:n1,float32,blocks.4.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741957 88 grad.cc:77] grads[51] 'blocks.4.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2311:1:2:2:i1:o1:s0:n1,float32,blocks.4.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.741963 88 grad.cc:77] grads[52] 'blocks.4.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2320:1:2:2:i1:o1:s0:n1,float32,blocks.4.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741968 88 grad.cc:77] grads[53] 'blocks.4.norm2.weight' doesn't have gradient. It will be set to zero: Var(2331:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.741973 88 grad.cc:77] grads[54] 'blocks.4.norm2.bias' doesn't have gradient. It will be set to zero: Var(2326:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741978 88 grad.cc:77] grads[55] 'blocks.4.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2375:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.741983 88 grad.cc:77] grads[56] 'blocks.4.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2384:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.741989 88 grad.cc:77] grads[57] 'blocks.4.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2428:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.741994 88 grad.cc:77] grads[58] 'blocks.4.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2437:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.741999 88 grad.cc:77] grads[59] 'blocks.5.norm1.weight' doesn't have gradient. It will be set to zero: Var(2448:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742004 88 grad.cc:77] grads[60] 'blocks.5.norm1.bias' doesn't have gradient. It will be set to zero: Var(2443:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742009 88 grad.cc:77] grads[61] 'blocks.5.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2492:1:2:2:i1:o1:s0:n1,float32,blocks.5.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.742015 88 grad.cc:77] grads[62] 'blocks.5.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2539:1:2:2:i1:o1:s0:n1,float32,blocks.5.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.742020 88 grad.cc:77] grads[63] 'blocks.5.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2548:1:2:2:i1:o1:s0:n1,float32,blocks.5.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742027 88 grad.cc:77] grads[64] 'blocks.5.norm2.weight' doesn't have gradient. It will be set to zero: Var(2559:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742033 88 grad.cc:77] grads[65] 'blocks.5.norm2.bias' doesn't have gradient. It will be set to zero: Var(2554:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742038 88 grad.cc:77] grads[66] 'blocks.5.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2603:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.742043 88 grad.cc:77] grads[67] 'blocks.5.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2612:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.742049 88 grad.cc:77] grads[68] 'blocks.5.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2656:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.742054 88 grad.cc:77] grads[69] 'blocks.5.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2665:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742059 88 grad.cc:77] grads[70] 'blocks.6.norm1.weight' doesn't have gradient. It will be set to zero: Var(2676:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742064 88 grad.cc:77] grads[71] 'blocks.6.norm1.bias' doesn't have gradient. It will be set to zero: Var(2671:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742070 88 grad.cc:77] grads[72] 'blocks.6.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2720:1:2:2:i1:o1:s0:n1,float32,blocks.6.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.742075 88 grad.cc:77] grads[73] 'blocks.6.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2767:1:2:2:i1:o1:s0:n1,float32,blocks.6.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.742081 88 grad.cc:77] grads[74] 'blocks.6.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2776:1:2:2:i1:o1:s0:n1,float32,blocks.6.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742086 88 grad.cc:77] grads[75] 'blocks.6.norm2.weight' doesn't have gradient. It will be set to zero: Var(2787:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742094 88 grad.cc:77] grads[76] 'blocks.6.norm2.bias' doesn't have gradient. It will be set to zero: Var(2782:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742099 88 grad.cc:77] grads[77] 'blocks.6.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2831:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.742106 88 grad.cc:77] grads[78] 'blocks.6.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2840:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.742112 88 grad.cc:77] grads[79] 'blocks.6.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2884:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.742117 88 grad.cc:77] grads[80] 'blocks.6.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2893:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742123 88 grad.cc:77] grads[81] 'blocks.7.norm1.weight' doesn't have gradient. It will be set to zero: Var(2904:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742127 88 grad.cc:77] grads[82] 'blocks.7.norm1.bias' doesn't have gradient. It will be set to zero: Var(2899:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742133 88 grad.cc:77] grads[83] 'blocks.7.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2948:1:2:2:i1:o1:s0:n1,float32,blocks.7.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.742140 88 grad.cc:77] grads[84] 'blocks.7.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2995:1:2:2:i1:o1:s0:n1,float32,blocks.7.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:47:24.742153 88 grad.cc:77] grads[85] 'blocks.7.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(3004:1:2:2:i1:o1:s0:n1,float32,blocks.7.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742159 88 grad.cc:77] grads[86] 'blocks.7.norm2.weight' doesn't have gradient. It will be set to zero: Var(3015:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742164 88 grad.cc:77] grads[87] 'blocks.7.norm2.bias' doesn't have gradient. It will be set to zero: Var(3010:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742170 88 grad.cc:77] grads[88] 'blocks.7.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(3059:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:47:24.742176 88 grad.cc:77] grads[89] 'blocks.7.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(3068:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:47:24.742181 88 grad.cc:77] grads[90] 'blocks.7.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(3112:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:47:24.742186 88 grad.cc:77] grads[91] 'blocks.7.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(3121:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742191 88 grad.cc:77] grads[92] 'norm.weight' doesn't have gradient. It will be set to zero: Var(3132:1:2:2:i1:o1:s0:n1,float32,norm.weight,0)[768,][m
[38;5;3m[w 0509 19:47:24.742196 88 grad.cc:77] grads[93] 'norm.bias' doesn't have gradient. It will be set to zero: Var(3127:1:2:2:i1:o1:s0:n1,float32,norm.bias,0)[768,][m
[38;5;3m[w 0509 19:47:24.742201 88 grad.cc:77] grads[94] 'head.weight' doesn't have gradient. It will be set to zero: Var(3176:1:2:2:i1:o1:s0:n1,float32,head.weight,0)[102,768,][m
[38;5;3m[w 0509 19:47:24.742206 88 grad.cc:77] grads[95] 'head.bias' doesn't have gradient. It will be set to zero: Var(3185:1:2:2:i1:o1:s0:n1,float32,head.bias,0)[102,][m
epoch: 0 validateAccuracy: 0.0725 trainAccuracy: 0.0471 delta: 0.0725
Training:   0%|          | 1/200 [00:22<1:14:08, 22.36s/it]epoch: 1 validateAccuracy: 0.1431 trainAccuracy: 0.0951 delta: 0.0706
Training:   1%|          | 2/200 [00:43<1:11:24, 21.64s/it]epoch: 2 validateAccuracy: 0.1392 trainAccuracy: 0.1176 delta: -0.0039
Training:   2%|â–         | 3/200 [01:01<1:05:31, 19.96s/it]epoch: 3 validateAccuracy: 0.1627 trainAccuracy: 0.1804 delta: 0.0196
Training:   2%|â–         | 4/200 [01:22<1:06:14, 20.28s/it]epoch: 4 validateAccuracy: 0.2245 trainAccuracy: 0.2373 delta: 0.0618
Training:   2%|â–Ž         | 5/200 [01:43<1:06:59, 20.61s/it]epoch: 5 validateAccuracy: 0.25 trainAccuracy: 0.3167 delta: 0.0255
Training:   3%|â–Ž         | 6/200 [02:04<1:06:49, 20.67s/it]epoch: 6 validateAccuracy: 0.2804 trainAccuracy: 0.3382 delta: 0.0304
Training:   4%|â–Ž         | 7/200 [02:25<1:06:50, 20.78s/it]epoch: 7 validateAccuracy: 0.2686 trainAccuracy: 0.3971 delta: -0.0118
Training:   4%|â–         | 8/200 [02:43<1:03:45, 19.92s/it]epoch: 8 validateAccuracy: 0.3029 trainAccuracy: 0.4706 delta: 0.0225
Training:   4%|â–         | 9/200 [03:04<1:04:17, 20.20s/it]epoch: 9 validateAccuracy: 0.3049 trainAccuracy: 0.5049 delta: 0.002
Training:   5%|â–Œ         | 10/200 [03:25<1:04:41, 20.43s/it]epoch: 10 validateAccuracy: 0.3304 trainAccuracy: 0.5745 delta: 0.0255
Training:   6%|â–Œ         | 11/200 [03:46<1:04:57, 20.62s/it]epoch: 11 validateAccuracy: 0.3294 trainAccuracy: 0.6284 delta: -0.001
Training:   6%|â–Œ         | 12/200 [04:03<1:01:57, 19.77s/it]epoch: 12 validateAccuracy: 0.3539 trainAccuracy: 0.6853 delta: 0.0235
Training:   6%|â–‹         | 13/200 [04:24<1:02:48, 20.15s/it]epoch: 13 validateAccuracy: 0.351 trainAccuracy: 0.7431 delta: -0.0029
Training:   7%|â–‹         | 14/200 [04:42<1:00:27, 19.50s/it]epoch: 14 validateAccuracy: 0.3539 trainAccuracy: 0.7706 delta: 0.0
Training:   8%|â–Š         | 15/200 [05:00<58:37, 19.01s/it]  epoch: 15 validateAccuracy: 0.3618 trainAccuracy: 0.8265 delta: 0.0079
Training:   8%|â–Š         | 16/200 [05:21<59:44, 19.48s/it]epoch: 16 validateAccuracy: 0.3627 trainAccuracy: 0.8363 delta: 0.0009
Training:   8%|â–Š         | 17/200 [05:42<1:00:43, 19.91s/it]epoch: 17 validateAccuracy: 0.3598 trainAccuracy: 0.8716 delta: -0.0029
Training:   9%|â–‰         | 18/200 [06:00<58:34, 19.31s/it]  epoch: 18 validateAccuracy: 0.3667 trainAccuracy: 0.8696 delta: 0.004
Training:  10%|â–‰         | 19/200 [06:21<59:37, 19.77s/it]epoch: 19 validateAccuracy: 0.3578 trainAccuracy: 0.8706 delta: -0.0089
Training:  10%|â–ˆ         | 20/200 [06:39<57:43, 19.24s/it]epoch: 20 validateAccuracy: 0.349 trainAccuracy: 0.8824 delta: -0.0177
Training:  10%|â–ˆ         | 21/200 [06:57<56:17, 18.87s/it]epoch: 21 validateAccuracy: 0.35 trainAccuracy: 0.8627 delta: -0.0167
Training:  11%|â–ˆ         | 22/200 [07:14<55:03, 18.56s/it]epoch: 22 validateAccuracy: 0.349 trainAccuracy: 0.8627 delta: -0.0177
Training:  12%|â–ˆâ–        | 23/200 [07:32<54:10, 18.36s/it]epoch: 23 validateAccuracy: 0.3578 trainAccuracy: 0.8461 delta: -0.0089
Training:  12%|â–ˆâ–        | 24/200 [07:50<53:33, 18.26s/it]epoch: 24 validateAccuracy: 0.3343 trainAccuracy: 0.8294 delta: -0.0324
Training:  12%|â–ˆâ–Ž        | 25/200 [08:08<52:55, 18.14s/it]epoch: 25 validateAccuracy: 0.3265 trainAccuracy: 0.798 delta: -0.0402
Training:  13%|â–ˆâ–Ž        | 26/200 [08:26<52:34, 18.13s/it]epoch: 26 validateAccuracy: 0.3118 trainAccuracy: 0.85 delta: -0.0549
Training:  14%|â–ˆâ–Ž        | 27/200 [08:44<52:07, 18.08s/it]epoch: 27 validateAccuracy: 0.3382 trainAccuracy: 0.8069 delta: -0.0285
Training:  14%|â–ˆâ–        | 28/200 [09:02<51:42, 18.04s/it]epoch: 28 validateAccuracy: 0.3422 trainAccuracy: 0.852 delta: -0.0245
Training:  14%|â–ˆâ–        | 29/200 [09:20<51:27, 18.05s/it]epoch: 29 validateAccuracy: 0.351 trainAccuracy: 0.8676 delta: -0.0157
Training:  15%|â–ˆâ–Œ        | 30/200 [09:38<51:08, 18.05s/it]epoch: 30 validateAccuracy: 0.3294 trainAccuracy: 0.8873 delta: -0.0373
Training:  16%|â–ˆâ–Œ        | 31/200 [09:59<52:37, 18.68s/it]epoch: 31 validateAccuracy: 0.3147 trainAccuracy: 0.8598 delta: -0.052
Training:  16%|â–ˆâ–Œ        | 32/200 [10:20<54:20, 19.41s/it]epoch: 32 validateAccuracy: 0.3284 trainAccuracy: 0.8745 delta: -0.0383
Training:  16%|â–ˆâ–‹        | 33/200 [10:41<55:50, 20.06s/it]epoch: 33 validateAccuracy: 0.3088 trainAccuracy: 0.8941 delta: -0.0579
Training:  17%|â–ˆâ–‹        | 34/200 [11:03<57:08, 20.65s/it]epoch: 34 validateAccuracy: 0.3588 trainAccuracy: 0.9216 delta: -0.0079
Training:  18%|â–ˆâ–Š        | 35/200 [11:25<58:05, 21.13s/it]epoch: 35 validateAccuracy: 0.3647 trainAccuracy: 0.9569 delta: -0.002
Training:  18%|â–ˆâ–Š        | 36/200 [11:47<58:00, 21.23s/it]epoch: 36 validateAccuracy: 0.3588 trainAccuracy: 0.9529 delta: -0.0079
Training:  18%|â–ˆâ–Š        | 37/200 [12:09<58:02, 21.36s/it]epoch: 37 validateAccuracy: 0.3784 trainAccuracy: 0.9725 delta: 0.0117
Training:  19%|â–ˆâ–‰        | 38/200 [12:33<1:00:03, 22.24s/it]epoch: 38 validateAccuracy: 0.3745 trainAccuracy: 0.9814 delta: -0.0039
Training:  20%|â–ˆâ–‰        | 39/200 [12:58<1:01:44, 23.01s/it]epoch: 39 validateAccuracy: 0.3676 trainAccuracy: 0.9775 delta: -0.0108
Training:  20%|â–ˆâ–ˆ        | 40/200 [13:22<1:02:46, 23.54s/it]epoch: 40 validateAccuracy: 0.3833 trainAccuracy: 0.9961 delta: 0.0049
Training:  20%|â–ˆâ–ˆ        | 41/200 [13:52<1:07:23, 25.43s/it]epoch: 41 validateAccuracy: 0.3794 trainAccuracy: 0.998 delta: -0.0039
Training:  21%|â–ˆâ–ˆ        | 42/200 [14:18<1:07:09, 25.50s/it]epoch: 42 validateAccuracy: 0.3814 trainAccuracy: 0.998 delta: -0.0019
Training:  22%|â–ˆâ–ˆâ–       | 43/200 [14:43<1:06:17, 25.34s/it]epoch: 43 validateAccuracy: 0.3804 trainAccuracy: 0.999 delta: -0.0029
Training:  22%|â–ˆâ–ˆâ–       | 44/200 [15:09<1:06:17, 25.50s/it]epoch: 44 validateAccuracy: 0.3863 trainAccuracy: 0.999 delta: 0.003
Training:  22%|â–ˆâ–ˆâ–Ž       | 45/200 [15:37<1:07:39, 26.19s/it]epoch: 45 validateAccuracy: 0.3843 trainAccuracy: 0.999 delta: -0.002
Training:  23%|â–ˆâ–ˆâ–Ž       | 46/200 [16:02<1:06:51, 26.05s/it]epoch: 46 validateAccuracy: 0.3775 trainAccuracy: 0.9971 delta: -0.0088
Training:  24%|â–ˆâ–ˆâ–Ž       | 47/200 [16:28<1:06:11, 25.96s/it]epoch: 47 validateAccuracy: 0.3873 trainAccuracy: 0.9951 delta: 0.001
Training:  24%|â–ˆâ–ˆâ–       | 48/200 [16:58<1:08:53, 27.19s/it]epoch: 48 validateAccuracy: 0.3873 trainAccuracy: 0.9971 delta: 0.0
Training:  24%|â–ˆâ–ˆâ–       | 49/200 [17:24<1:07:26, 26.80s/it]epoch: 49 validateAccuracy: 0.3882 trainAccuracy: 0.999 delta: 0.0009
Training:  25%|â–ˆâ–ˆâ–Œ       | 50/200 [17:53<1:08:44, 27.50s/it]epoch: 50 validateAccuracy: 0.3804 trainAccuracy: 0.999 delta: -0.0078
Training:  26%|â–ˆâ–ˆâ–Œ       | 51/200 [18:19<1:07:10, 27.05s/it]epoch: 51 validateAccuracy: 0.3892 trainAccuracy: 0.999 delta: 0.001
Training:  26%|â–ˆâ–ˆâ–Œ       | 52/200 [18:48<1:08:10, 27.64s/it]epoch: 52 validateAccuracy: 0.3735 trainAccuracy: 0.9912 delta: -0.0157
Training:  26%|â–ˆâ–ˆâ–‹       | 53/200 [19:15<1:07:07, 27.40s/it]epoch: 53 validateAccuracy: 0.3725 trainAccuracy: 0.9853 delta: -0.0167
Training:  27%|â–ˆâ–ˆâ–‹       | 54/200 [19:41<1:05:56, 27.10s/it]epoch: 54 validateAccuracy: 0.3294 trainAccuracy: 0.9676 delta: -0.0598
Training:  28%|â–ˆâ–ˆâ–Š       | 55/200 [20:07<1:04:37, 26.74s/it]epoch: 55 validateAccuracy: 0.3412 trainAccuracy: 0.9392 delta: -0.048
Training:  28%|â–ˆâ–ˆâ–Š       | 56/200 [20:33<1:03:34, 26.49s/it]epoch: 56 validateAccuracy: 0.3451 trainAccuracy: 0.9137 delta: -0.0441
Training:  28%|â–ˆâ–ˆâ–Š       | 57/200 [20:59<1:02:55, 26.40s/it]epoch: 57 validateAccuracy: 0.3363 trainAccuracy: 0.8441 delta: -0.0529
Training:  29%|â–ˆâ–ˆâ–‰       | 58/200 [21:25<1:02:03, 26.22s/it]epoch: 58 validateAccuracy: 0.348 trainAccuracy: 0.8833 delta: -0.0412
Training:  30%|â–ˆâ–ˆâ–‰       | 59/200 [21:51<1:01:23, 26.13s/it]epoch: 59 validateAccuracy: 0.3373 trainAccuracy: 0.8843 delta: -0.0519
Training:  30%|â–ˆâ–ˆâ–ˆ       | 60/200 [22:17<1:01:00, 26.15s/it]epoch: 60 validateAccuracy: 0.3373 trainAccuracy: 0.9216 delta: -0.0519
Training:  30%|â–ˆâ–ˆâ–ˆ       | 61/200 [22:43<1:00:21, 26.05s/it]epoch: 61 validateAccuracy: 0.3422 trainAccuracy: 0.9422 delta: -0.047
Training:  31%|â–ˆâ–ˆâ–ˆ       | 62/200 [23:10<1:00:13, 26.19s/it]epoch: 62 validateAccuracy: 0.351 trainAccuracy: 0.9451 delta: -0.0382
Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [23:36<1:00:07, 26.33s/it]epoch: 63 validateAccuracy: 0.3598 trainAccuracy: 0.952 delta: -0.0294
Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [24:02<59:29, 26.25s/it]  epoch: 64 validateAccuracy: 0.3569 trainAccuracy: 0.9627 delta: -0.0323
Training:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [24:29<59:23, 26.40s/it]epoch: 65 validateAccuracy: 0.35 trainAccuracy: 0.9618 delta: -0.0392
Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [24:55<58:27, 26.18s/it]epoch: 66 validateAccuracy: 0.3824 trainAccuracy: 0.9706 delta: -0.0068
Training:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [25:21<57:56, 26.14s/it]epoch: 67 validateAccuracy: 0.3637 trainAccuracy: 0.9784 delta: -0.0255
Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [25:47<57:44, 26.25s/it]epoch: 68 validateAccuracy: 0.3833 trainAccuracy: 0.9892 delta: -0.0059
Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [26:13<57:05, 26.15s/it]epoch: 69 validateAccuracy: 0.3941 trainAccuracy: 0.9971 delta: 0.0049
Training:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [26:42<58:36, 27.05s/it]epoch: 70 validateAccuracy: 0.3971 trainAccuracy: 0.999 delta: 0.003
Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [27:12<59:30, 27.68s/it]epoch: 71 validateAccuracy: 0.3922 trainAccuracy: 1.0 delta: -0.0049
Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [27:38<58:24, 27.38s/it]epoch: 72 validateAccuracy: 0.3892 trainAccuracy: 1.0 delta: -0.0079
Training:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [28:05<57:34, 27.20s/it]epoch: 73 validateAccuracy: 0.3931 trainAccuracy: 1.0 delta: -0.004
Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [28:32<56:44, 27.02s/it]epoch: 74 validateAccuracy: 0.3922 trainAccuracy: 0.999 delta: -0.0049
Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [28:57<55:15, 26.53s/it]epoch: 75 validateAccuracy: 0.3951 trainAccuracy: 0.999 delta: -0.002
Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [29:23<54:40, 26.45s/it]epoch: 76 validateAccuracy: 0.3902 trainAccuracy: 1.0 delta: -0.0069
Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [29:50<54:16, 26.48s/it]epoch: 77 validateAccuracy: 0.3922 trainAccuracy: 1.0 delta: -0.0049
Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [30:16<53:48, 26.46s/it]epoch: 78 validateAccuracy: 0.3922 trainAccuracy: 1.0 delta: -0.0049
Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [30:42<52:58, 26.27s/it]epoch: 79 validateAccuracy: 0.3931 trainAccuracy: 1.0 delta: -0.004
Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [31:08<52:10, 26.09s/it]epoch: 80 validateAccuracy: 0.3902 trainAccuracy: 0.998 delta: -0.0069
Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [31:34<52:01, 26.23s/it]epoch: 81 validateAccuracy: 0.3931 trainAccuracy: 0.999 delta: -0.004
Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [32:01<51:57, 26.42s/it]epoch: 82 validateAccuracy: 0.3961 trainAccuracy: 0.998 delta: -0.001
Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [32:27<51:24, 26.36s/it]epoch: 83 validateAccuracy: 0.3902 trainAccuracy: 1.0 delta: -0.0069
Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [32:54<51:03, 26.41s/it]epoch: 84 validateAccuracy: 0.3873 trainAccuracy: 1.0 delta: -0.0098
Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [33:20<50:21, 26.27s/it]epoch: 85 validateAccuracy: 0.3833 trainAccuracy: 1.0 delta: -0.0138
Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [33:46<50:02, 26.34s/it]epoch: 86 validateAccuracy: 0.3549 trainAccuracy: 0.9951 delta: -0.0422
Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [34:12<49:29, 26.28s/it]epoch: 87 validateAccuracy: 0.3265 trainAccuracy: 0.9196 delta: -0.0706
Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [34:39<49:07, 26.32s/it]epoch: 88 validateAccuracy: 0.301 trainAccuracy: 0.8088 delta: -0.0961
Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [35:05<48:45, 26.36s/it]epoch: 89 validateAccuracy: 0.3196 trainAccuracy: 0.7971 delta: -0.0775
Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [35:32<48:23, 26.39s/it]epoch: 90 validateAccuracy: 0.3294 trainAccuracy: 0.8647 delta: -0.0677
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [35:58<47:56, 26.39s/it]epoch: 91 validateAccuracy: 0.3471 trainAccuracy: 0.9275 delta: -0.05
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [36:25<47:46, 26.54s/it]epoch: 92 validateAccuracy: 0.3686 trainAccuracy: 0.9431 delta: -0.0285
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [36:52<47:28, 26.62s/it]epoch: 93 validateAccuracy: 0.3598 trainAccuracy: 0.9667 delta: -0.0373
Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [37:18<47:00, 26.61s/it]epoch: 94 validateAccuracy: 0.352 trainAccuracy: 0.9667 delta: -0.0451
Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [37:45<46:39, 26.66s/it]epoch: 95 validateAccuracy: 0.348 trainAccuracy: 0.9725 delta: -0.0491
Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [38:12<46:21, 26.74s/it]epoch: 96 validateAccuracy: 0.3775 trainAccuracy: 0.9833 delta: -0.0196
Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [38:39<45:49, 26.69s/it]epoch: 97 validateAccuracy: 0.3824 trainAccuracy: 0.9971 delta: -0.0147
Training:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [39:05<45:19, 26.66s/it]epoch: 98 validateAccuracy: 0.3833 trainAccuracy: 1.0 delta: -0.0138
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [39:32<44:42, 26.56s/it]epoch: 99 validateAccuracy: 0.3863 trainAccuracy: 0.9971 delta: -0.0108
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [39:58<44:22, 26.63s/it]epoch: 100 validateAccuracy: 0.3853 trainAccuracy: 0.998 delta: -0.0118
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [40:25<43:46, 26.53s/it]epoch: 101 validateAccuracy: 0.3804 trainAccuracy: 0.999 delta: -0.0167
Training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [40:51<43:12, 26.45s/it]epoch: 102 validateAccuracy: 0.3784 trainAccuracy: 0.998 delta: -0.0187
Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [41:17<42:44, 26.44s/it]epoch: 103 validateAccuracy: 0.3843 trainAccuracy: 0.999 delta: -0.0128
Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [41:44<42:16, 26.42s/it]epoch: 104 validateAccuracy: 0.3863 trainAccuracy: 1.0 delta: -0.0108
Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [42:10<41:43, 26.35s/it]epoch: 105 validateAccuracy: 0.3902 trainAccuracy: 0.999 delta: -0.0069
Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [42:36<41:01, 26.19s/it]epoch: 106 validateAccuracy: 0.3882 trainAccuracy: 1.0 delta: -0.0089
Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [43:02<40:35, 26.19s/it]epoch: 107 validateAccuracy: 0.3892 trainAccuracy: 0.999 delta: -0.0079
Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [43:29<40:18, 26.29s/it]epoch: 108 validateAccuracy: 0.3863 trainAccuracy: 1.0 delta: -0.0108
Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [43:55<39:48, 26.25s/it]epoch: 109 validateAccuracy: 0.3941 trainAccuracy: 0.999 delta: -0.003
Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [44:21<39:14, 26.16s/it]epoch: 110 validateAccuracy: 0.3922 trainAccuracy: 0.999 delta: -0.0049
Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [44:47<38:54, 26.23s/it]epoch: 111 validateAccuracy: 0.3912 trainAccuracy: 1.0 delta: -0.0059
Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [45:13<38:21, 26.16s/it]epoch: 112 validateAccuracy: 0.3863 trainAccuracy: 1.0 delta: -0.0108
Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [45:39<38:00, 26.21s/it]epoch: 113 validateAccuracy: 0.3873 trainAccuracy: 1.0 delta: -0.0098
Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [46:05<37:31, 26.18s/it]epoch: 114 validateAccuracy: 0.3647 trainAccuracy: 0.9843 delta: -0.0324
Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [46:32<37:08, 26.22s/it]epoch: 115 validateAccuracy: 0.3627 trainAccuracy: 0.9696 delta: -0.0344
Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [46:58<36:43, 26.23s/it]epoch: 116 validateAccuracy: 0.3441 trainAccuracy: 0.9539 delta: -0.053
Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [47:24<36:20, 26.27s/it]epoch: 117 validateAccuracy: 0.3324 trainAccuracy: 0.8931 delta: -0.0647
Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [47:50<35:48, 26.20s/it]epoch: 118 validateAccuracy: 0.3373 trainAccuracy: 0.8353 delta: -0.0598
Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [48:17<35:26, 26.26s/it]epoch: 119 validateAccuracy: 0.3333 trainAccuracy: 0.8892 delta: -0.0638
Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [48:43<35:01, 26.27s/it]epoch: 120 validateAccuracy: 0.3343 trainAccuracy: 0.9461 delta: -0.0628
Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [49:10<32:46, 24.58s/it]
