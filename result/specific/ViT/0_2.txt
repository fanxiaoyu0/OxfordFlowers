[38;5;2m[i 0509 19:57:07.329424 56 compiler.py:951] Jittor(1.3.3.14) src: /home/prs01/miniconda3/envs/jittor/lib/python3.7/site-packages/jittor[m
[38;5;2m[i 0509 19:57:07.345258 56 compiler.py:952] g++ at /usr/bin/g++(9.4.0)[m
[38;5;2m[i 0509 19:57:07.345388 56 compiler.py:953] cache_path: /home/prs01/.cache/jittor/jt1.3.3/g++9.4.0/py3.7.13/Linux-5.4.0-10xc4/IntelRXeonRGolx7a/default[m
[38;5;2m[i 0509 19:57:07.393150 56 install_cuda.py:53] cuda_driver_version: [11, 6][m
[38;5;2m[i 0509 19:57:07.411157 56 __init__.py:411] Found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/bin/nvcc(11.2.152) at /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/bin/nvcc.[m
[38;5;2m[i 0509 19:57:07.427393 56 __init__.py:411] Found addr2line(2.34) at /usr/bin/addr2line.[m
[38;5;2m[i 0509 19:57:07.619481 56 compiler.py:1006] cuda key:cu11.2.152_sm_86[m
[38;5;2m[i 0509 19:57:07.920133 56 __init__.py:227] Total mem: 251.56GB, using 16 procs for compiling.[m
[38;5;2m[i 0509 19:57:08.054352 56 jit_compiler.cc:28] Load cc_path: /usr/bin/g++[m
[38;5;2m[i 0509 19:57:08.196418 56 init.cc:62] Found cuda archs: [86,][m
[38;5;2m[i 0509 19:57:08.341620 56 compile_extern.py:516] mpicc not found, distribution disabled.[m
[38;5;2m[i 0509 19:57:08.427250 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/cublas.h[m
[38;5;2m[i 0509 19:57:08.453370 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcublas.so[m
[38;5;2m[i 0509 19:57:08.453608 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcublasLt.so.11[m
[38;5;2m[i 0509 19:57:09.464588 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/cudnn.h[m
[38;5;2m[i 0509 19:57:09.501472 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn.so.8[m
[38;5;2m[i 0509 19:57:09.501603 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_ops_infer.so.8[m
[38;5;2m[i 0509 19:57:09.517205 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_ops_train.so.8[m
[38;5;2m[i 0509 19:57:09.525032 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_cnn_infer.so.8[m
[38;5;2m[i 0509 19:57:09.563992 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcudnn_cnn_train.so.8[m
[38;5;2m[i 0509 19:57:10.441028 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/curand.h[m
[38;5;2m[i 0509 19:57:10.539416 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcurand.so[m
[38;5;2m[i 0509 19:57:10.565269 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/include/cufft.h[m
[38;5;2m[i 0509 19:57:10.755744 56 compile_extern.py:30] found /home/prs01/.cache/jittor/jtcuda/cuda11.2_cudnn8_linux/lib64/libcufft.so[m
[38;5;2m[i 0509 19:57:10.946245 56 cuda_flags.cc:32] CUDA enabled.[m
Loading data...
[38;5;2m[i 0509 19:57:11.012830 56 dataset.py:631] Found 102 classes and 1020 images.[m
[38;5;2m[i 0509 19:57:11.040007 56 dataset.py:631] Found 102 classes and 1020 images.[m
[38;5;2m[i 0509 19:57:11.112116 56 dataset.py:631] Found 102 classes and 6149 images.[m
----------------- A new trial ---------------------
modelName ViT learning rate: 5e-05 etaMin 1e-05 imgSize 224 batchSize 64 savedName 0_2.pkl criterion CrossEntropyLoss weight_decay 0.001 TMax 15
Training:   0%|          | 0/200 [00:00<?, ?it/s][38;5;3m[w 0509 19:57:11.710846 56 grad.cc:77] grads[0] 'cls_token' doesn't have gradient. It will be set to zero: Var(1294:1:2:2:i1:o1:s0:n1,float32,cls_token,0)[1,1,768,][m
[38;5;3m[w 0509 19:57:11.710886 56 grad.cc:77] grads[1] 'pos_embed' doesn't have gradient. It will be set to zero: Var(1247:1:2:2:i1:o1:s0:n1,float32,pos_embed,0)[1,197,768,][m
[38;5;3m[w 0509 19:57:11.710894 56 grad.cc:77] grads[2] 'patch_embed.proj.weight' doesn't have gradient. It will be set to zero: Var(15:1:2:2:i1:o1:s0:n1,float32,patch_embed.proj.weight,0)[768,3,16,16,][m
[38;5;3m[w 0509 19:57:11.710904 56 grad.cc:77] grads[3] 'patch_embed.proj.bias' doesn't have gradient. It will be set to zero: Var(32:1:2:2:i1:o1:s0:n1,float32,patch_embed.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.710910 56 grad.cc:77] grads[4] 'blocks.0.norm1.weight' doesn't have gradient. It will be set to zero: Var(1308:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.710915 56 grad.cc:77] grads[5] 'blocks.0.norm1.bias' doesn't have gradient. It will be set to zero: Var(1303:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.710920 56 grad.cc:77] grads[6] 'blocks.0.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(1352:1:2:2:i1:o1:s0:n1,float32,blocks.0.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.710925 56 grad.cc:77] grads[7] 'blocks.0.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(1399:1:2:2:i1:o1:s0:n1,float32,blocks.0.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.710931 56 grad.cc:77] grads[8] 'blocks.0.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(1408:1:2:2:i1:o1:s0:n1,float32,blocks.0.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727453 56 grad.cc:77] grads[9] 'blocks.0.norm2.weight' doesn't have gradient. It will be set to zero: Var(1419:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.727478 56 grad.cc:77] grads[10] 'blocks.0.norm2.bias' doesn't have gradient. It will be set to zero: Var(1414:1:2:2:i1:o1:s0:n1,float32,blocks.0.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727490 56 grad.cc:77] grads[11] 'blocks.0.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(1463:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.727502 56 grad.cc:77] grads[12] 'blocks.0.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(1472:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.727514 56 grad.cc:77] grads[13] 'blocks.0.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(1516:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.727525 56 grad.cc:77] grads[14] 'blocks.0.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(1525:1:2:2:i1:o1:s0:n1,float32,blocks.0.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727536 56 grad.cc:77] grads[15] 'blocks.1.norm1.weight' doesn't have gradient. It will be set to zero: Var(1536:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.727547 56 grad.cc:77] grads[16] 'blocks.1.norm1.bias' doesn't have gradient. It will be set to zero: Var(1531:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727558 56 grad.cc:77] grads[17] 'blocks.1.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(1580:1:2:2:i1:o1:s0:n1,float32,blocks.1.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.727570 56 grad.cc:77] grads[18] 'blocks.1.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(1627:1:2:2:i1:o1:s0:n1,float32,blocks.1.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.727581 56 grad.cc:77] grads[19] 'blocks.1.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(1636:1:2:2:i1:o1:s0:n1,float32,blocks.1.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727593 56 grad.cc:77] grads[20] 'blocks.1.norm2.weight' doesn't have gradient. It will be set to zero: Var(1647:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.727602 56 grad.cc:77] grads[21] 'blocks.1.norm2.bias' doesn't have gradient. It will be set to zero: Var(1642:1:2:2:i1:o1:s0:n1,float32,blocks.1.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727614 56 grad.cc:77] grads[22] 'blocks.1.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(1691:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.727631 56 grad.cc:77] grads[23] 'blocks.1.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(1700:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.727643 56 grad.cc:77] grads[24] 'blocks.1.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(1744:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.727654 56 grad.cc:77] grads[25] 'blocks.1.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(1753:1:2:2:i1:o1:s0:n1,float32,blocks.1.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727665 56 grad.cc:77] grads[26] 'blocks.2.norm1.weight' doesn't have gradient. It will be set to zero: Var(1764:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.727676 56 grad.cc:77] grads[27] 'blocks.2.norm1.bias' doesn't have gradient. It will be set to zero: Var(1759:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727687 56 grad.cc:77] grads[28] 'blocks.2.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(1808:1:2:2:i1:o1:s0:n1,float32,blocks.2.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.727697 56 grad.cc:77] grads[29] 'blocks.2.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(1855:1:2:2:i1:o1:s0:n1,float32,blocks.2.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.727709 56 grad.cc:77] grads[30] 'blocks.2.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(1864:1:2:2:i1:o1:s0:n1,float32,blocks.2.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727719 56 grad.cc:77] grads[31] 'blocks.2.norm2.weight' doesn't have gradient. It will be set to zero: Var(1875:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.727730 56 grad.cc:77] grads[32] 'blocks.2.norm2.bias' doesn't have gradient. It will be set to zero: Var(1870:1:2:2:i1:o1:s0:n1,float32,blocks.2.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.727742 56 grad.cc:77] grads[33] 'blocks.2.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(1919:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.738507 56 grad.cc:77] grads[34] 'blocks.2.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(1928:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.738536 56 grad.cc:77] grads[35] 'blocks.2.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(1972:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.738553 56 grad.cc:77] grads[36] 'blocks.2.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(1981:1:2:2:i1:o1:s0:n1,float32,blocks.2.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.738569 56 grad.cc:77] grads[37] 'blocks.3.norm1.weight' doesn't have gradient. It will be set to zero: Var(1992:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.738584 56 grad.cc:77] grads[38] 'blocks.3.norm1.bias' doesn't have gradient. It will be set to zero: Var(1987:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.738600 56 grad.cc:77] grads[39] 'blocks.3.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2036:1:2:2:i1:o1:s0:n1,float32,blocks.3.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.738615 56 grad.cc:77] grads[40] 'blocks.3.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2083:1:2:2:i1:o1:s0:n1,float32,blocks.3.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.750592 56 grad.cc:77] grads[41] 'blocks.3.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2092:1:2:2:i1:o1:s0:n1,float32,blocks.3.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750612 56 grad.cc:77] grads[42] 'blocks.3.norm2.weight' doesn't have gradient. It will be set to zero: Var(2103:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.750628 56 grad.cc:77] grads[43] 'blocks.3.norm2.bias' doesn't have gradient. It will be set to zero: Var(2098:1:2:2:i1:o1:s0:n1,float32,blocks.3.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750638 56 grad.cc:77] grads[44] 'blocks.3.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2147:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.750647 56 grad.cc:77] grads[45] 'blocks.3.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2156:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.750656 56 grad.cc:77] grads[46] 'blocks.3.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2200:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.750665 56 grad.cc:77] grads[47] 'blocks.3.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2209:1:2:2:i1:o1:s0:n1,float32,blocks.3.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750674 56 grad.cc:77] grads[48] 'blocks.4.norm1.weight' doesn't have gradient. It will be set to zero: Var(2220:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.750683 56 grad.cc:77] grads[49] 'blocks.4.norm1.bias' doesn't have gradient. It will be set to zero: Var(2215:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750692 56 grad.cc:77] grads[50] 'blocks.4.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2264:1:2:2:i1:o1:s0:n1,float32,blocks.4.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.750700 56 grad.cc:77] grads[51] 'blocks.4.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2311:1:2:2:i1:o1:s0:n1,float32,blocks.4.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.750709 56 grad.cc:77] grads[52] 'blocks.4.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2320:1:2:2:i1:o1:s0:n1,float32,blocks.4.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750719 56 grad.cc:77] grads[53] 'blocks.4.norm2.weight' doesn't have gradient. It will be set to zero: Var(2331:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.750727 56 grad.cc:77] grads[54] 'blocks.4.norm2.bias' doesn't have gradient. It will be set to zero: Var(2326:1:2:2:i1:o1:s0:n1,float32,blocks.4.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750735 56 grad.cc:77] grads[55] 'blocks.4.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2375:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.750744 56 grad.cc:77] grads[56] 'blocks.4.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2384:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.750752 56 grad.cc:77] grads[57] 'blocks.4.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2428:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.750761 56 grad.cc:77] grads[58] 'blocks.4.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2437:1:2:2:i1:o1:s0:n1,float32,blocks.4.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750770 56 grad.cc:77] grads[59] 'blocks.5.norm1.weight' doesn't have gradient. It will be set to zero: Var(2448:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.750779 56 grad.cc:77] grads[60] 'blocks.5.norm1.bias' doesn't have gradient. It will be set to zero: Var(2443:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.750788 56 grad.cc:77] grads[61] 'blocks.5.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2492:1:2:2:i1:o1:s0:n1,float32,blocks.5.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.762439 56 grad.cc:77] grads[62] 'blocks.5.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2539:1:2:2:i1:o1:s0:n1,float32,blocks.5.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.762477 56 grad.cc:77] grads[63] 'blocks.5.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2548:1:2:2:i1:o1:s0:n1,float32,blocks.5.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.762509 56 grad.cc:77] grads[64] 'blocks.5.norm2.weight' doesn't have gradient. It will be set to zero: Var(2559:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.762530 56 grad.cc:77] grads[65] 'blocks.5.norm2.bias' doesn't have gradient. It will be set to zero: Var(2554:1:2:2:i1:o1:s0:n1,float32,blocks.5.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.762549 56 grad.cc:77] grads[66] 'blocks.5.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2603:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.762568 56 grad.cc:77] grads[67] 'blocks.5.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2612:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.762587 56 grad.cc:77] grads[68] 'blocks.5.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2656:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.762606 56 grad.cc:77] grads[69] 'blocks.5.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2665:1:2:2:i1:o1:s0:n1,float32,blocks.5.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.762625 56 grad.cc:77] grads[70] 'blocks.6.norm1.weight' doesn't have gradient. It will be set to zero: Var(2676:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.762657 56 grad.cc:77] grads[71] 'blocks.6.norm1.bias' doesn't have gradient. It will be set to zero: Var(2671:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.762678 56 grad.cc:77] grads[72] 'blocks.6.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2720:1:2:2:i1:o1:s0:n1,float32,blocks.6.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.773983 56 grad.cc:77] grads[73] 'blocks.6.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2767:1:2:2:i1:o1:s0:n1,float32,blocks.6.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.774031 56 grad.cc:77] grads[74] 'blocks.6.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(2776:1:2:2:i1:o1:s0:n1,float32,blocks.6.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.774049 56 grad.cc:77] grads[75] 'blocks.6.norm2.weight' doesn't have gradient. It will be set to zero: Var(2787:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.774064 56 grad.cc:77] grads[76] 'blocks.6.norm2.bias' doesn't have gradient. It will be set to zero: Var(2782:1:2:2:i1:o1:s0:n1,float32,blocks.6.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.774081 56 grad.cc:77] grads[77] 'blocks.6.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(2831:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.774098 56 grad.cc:77] grads[78] 'blocks.6.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(2840:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.774114 56 grad.cc:77] grads[79] 'blocks.6.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(2884:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.774129 56 grad.cc:77] grads[80] 'blocks.6.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(2893:1:2:2:i1:o1:s0:n1,float32,blocks.6.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.774144 56 grad.cc:77] grads[81] 'blocks.7.norm1.weight' doesn't have gradient. It will be set to zero: Var(2904:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm1.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.774159 56 grad.cc:77] grads[82] 'blocks.7.norm1.bias' doesn't have gradient. It will be set to zero: Var(2899:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm1.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.774174 56 grad.cc:77] grads[83] 'blocks.7.attn.qkv.weight' doesn't have gradient. It will be set to zero: Var(2948:1:2:2:i1:o1:s0:n1,float32,blocks.7.attn.qkv.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.774197 56 grad.cc:77] grads[84] 'blocks.7.attn.proj.weight' doesn't have gradient. It will be set to zero: Var(2995:1:2:2:i1:o1:s0:n1,float32,blocks.7.attn.proj.weight,0)[768,768,][m
[38;5;3m[w 0509 19:57:11.774213 56 grad.cc:77] grads[85] 'blocks.7.attn.proj.bias' doesn't have gradient. It will be set to zero: Var(3004:1:2:2:i1:o1:s0:n1,float32,blocks.7.attn.proj.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.774228 56 grad.cc:77] grads[86] 'blocks.7.norm2.weight' doesn't have gradient. It will be set to zero: Var(3015:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm2.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.774243 56 grad.cc:77] grads[87] 'blocks.7.norm2.bias' doesn't have gradient. It will be set to zero: Var(3010:1:2:2:i1:o1:s0:n1,float32,blocks.7.norm2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.774258 56 grad.cc:77] grads[88] 'blocks.7.mlp.fc1.weight' doesn't have gradient. It will be set to zero: Var(3059:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc1.weight,0)[2304,768,][m
[38;5;3m[w 0509 19:57:11.774274 56 grad.cc:77] grads[89] 'blocks.7.mlp.fc1.bias' doesn't have gradient. It will be set to zero: Var(3068:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc1.bias,0)[2304,][m
[38;5;3m[w 0509 19:57:11.785836 56 grad.cc:77] grads[90] 'blocks.7.mlp.fc2.weight' doesn't have gradient. It will be set to zero: Var(3112:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc2.weight,0)[768,2304,][m
[38;5;3m[w 0509 19:57:11.785871 56 grad.cc:77] grads[91] 'blocks.7.mlp.fc2.bias' doesn't have gradient. It will be set to zero: Var(3121:1:2:2:i1:o1:s0:n1,float32,blocks.7.mlp.fc2.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.785889 56 grad.cc:77] grads[92] 'norm.weight' doesn't have gradient. It will be set to zero: Var(3132:1:2:2:i1:o1:s0:n1,float32,norm.weight,0)[768,][m
[38;5;3m[w 0509 19:57:11.785908 56 grad.cc:77] grads[93] 'norm.bias' doesn't have gradient. It will be set to zero: Var(3127:1:2:2:i1:o1:s0:n1,float32,norm.bias,0)[768,][m
[38;5;3m[w 0509 19:57:11.785924 56 grad.cc:77] grads[94] 'head.weight' doesn't have gradient. It will be set to zero: Var(3176:1:2:2:i1:o1:s0:n1,float32,head.weight,0)[102,768,][m
[38;5;3m[w 0509 19:57:11.785940 56 grad.cc:77] grads[95] 'head.bias' doesn't have gradient. It will be set to zero: Var(3185:1:2:2:i1:o1:s0:n1,float32,head.bias,0)[102,][m
epoch: 0 validateAccuracy: 0.0775 trainAccuracy: 0.0392 delta: 0.0775
Training:   0%|          | 1/200 [00:27<1:30:26, 27.27s/it]epoch: 1 validateAccuracy: 0.1088 trainAccuracy: 0.0794 delta: 0.0313
Training:   1%|          | 2/200 [00:51<1:24:58, 25.75s/it]epoch: 2 validateAccuracy: 0.1529 trainAccuracy: 0.1412 delta: 0.0441
Training:   2%|â–         | 3/200 [01:17<1:23:39, 25.48s/it]epoch: 3 validateAccuracy: 0.2 trainAccuracy: 0.2049 delta: 0.0471
Training:   2%|â–         | 4/200 [01:42<1:23:15, 25.49s/it]epoch: 4 validateAccuracy: 0.2235 trainAccuracy: 0.251 delta: 0.0235
Training:   2%|â–Ž         | 5/200 [02:07<1:21:55, 25.21s/it]epoch: 5 validateAccuracy: 0.2353 trainAccuracy: 0.3206 delta: 0.0118
Training:   3%|â–Ž         | 6/200 [02:31<1:20:46, 24.98s/it]epoch: 6 validateAccuracy: 0.2676 trainAccuracy: 0.3608 delta: 0.0323
Training:   4%|â–Ž         | 7/200 [02:56<1:19:31, 24.72s/it]epoch: 7 validateAccuracy: 0.2843 trainAccuracy: 0.4108 delta: 0.0167
Training:   4%|â–         | 8/200 [03:25<1:23:31, 26.10s/it]epoch: 8 validateAccuracy: 0.2804 trainAccuracy: 0.5157 delta: -0.0039
Training:   4%|â–         | 9/200 [03:50<1:22:08, 25.80s/it]epoch: 9 validateAccuracy: 0.3118 trainAccuracy: 0.5529 delta: 0.0275
Training:   5%|â–Œ         | 10/200 [04:17<1:22:49, 26.16s/it]epoch: 10 validateAccuracy: 0.3245 trainAccuracy: 0.6167 delta: 0.0127
Training:   6%|â–Œ         | 11/200 [04:44<1:23:52, 26.63s/it]epoch: 11 validateAccuracy: 0.3098 trainAccuracy: 0.6794 delta: -0.0147
Training:   6%|â–Œ         | 12/200 [05:10<1:22:17, 26.26s/it]epoch: 12 validateAccuracy: 0.348 trainAccuracy: 0.7167 delta: 0.0235
Training:   6%|â–‹         | 13/200 [05:38<1:23:43, 26.86s/it]epoch: 13 validateAccuracy: 0.3314 trainAccuracy: 0.7647 delta: -0.0166
Training:   7%|â–‹         | 14/200 [06:03<1:21:05, 26.16s/it]epoch: 14 validateAccuracy: 0.3343 trainAccuracy: 0.8167 delta: -0.0137
Training:   8%|â–Š         | 15/200 [06:28<1:20:02, 25.96s/it]epoch: 15 validateAccuracy: 0.3382 trainAccuracy: 0.8422 delta: -0.0098
Training:   8%|â–Š         | 16/200 [06:53<1:18:28, 25.59s/it]epoch: 16 validateAccuracy: 0.3324 trainAccuracy: 0.8529 delta: -0.0156
Training:   8%|â–Š         | 17/200 [07:17<1:16:45, 25.16s/it]epoch: 17 validateAccuracy: 0.3431 trainAccuracy: 0.8941 delta: -0.0049
Training:   9%|â–‰         | 18/200 [07:43<1:16:42, 25.29s/it]epoch: 18 validateAccuracy: 0.348 trainAccuracy: 0.8941 delta: 0.0
Training:  10%|â–‰         | 19/200 [08:07<1:15:44, 25.11s/it]epoch: 19 validateAccuracy: 0.3529 trainAccuracy: 0.8971 delta: 0.0049
Training:  10%|â–ˆ         | 20/200 [08:36<1:18:13, 26.08s/it]epoch: 20 validateAccuracy: 0.3412 trainAccuracy: 0.899 delta: -0.0117
Training:  10%|â–ˆ         | 21/200 [09:02<1:17:44, 26.06s/it]epoch: 21 validateAccuracy: 0.3333 trainAccuracy: 0.901 delta: -0.0196
Training:  11%|â–ˆ         | 22/200 [09:28<1:17:43, 26.20s/it]epoch: 22 validateAccuracy: 0.3422 trainAccuracy: 0.8843 delta: -0.0107
Training:  12%|â–ˆâ–        | 23/200 [09:54<1:16:55, 26.08s/it]epoch: 23 validateAccuracy: 0.3539 trainAccuracy: 0.8824 delta: 0.001
Training:  12%|â–ˆâ–        | 24/200 [10:23<1:19:14, 27.01s/it]epoch: 24 validateAccuracy: 0.3324 trainAccuracy: 0.8735 delta: -0.0215
Training:  12%|â–ˆâ–Ž        | 25/200 [10:49<1:17:39, 26.62s/it]epoch: 25 validateAccuracy: 0.3412 trainAccuracy: 0.8892 delta: -0.0127
Training:  13%|â–ˆâ–Ž        | 26/200 [11:15<1:16:35, 26.41s/it]epoch: 26 validateAccuracy: 0.3137 trainAccuracy: 0.899 delta: -0.0402
Training:  14%|â–ˆâ–Ž        | 27/200 [11:40<1:15:01, 26.02s/it]epoch: 27 validateAccuracy: 0.3333 trainAccuracy: 0.8814 delta: -0.0206
Training:  14%|â–ˆâ–        | 28/200 [12:05<1:14:00, 25.82s/it]epoch: 28 validateAccuracy: 0.3529 trainAccuracy: 0.898 delta: -0.001
Training:  14%|â–ˆâ–        | 29/200 [12:31<1:13:18, 25.72s/it]epoch: 29 validateAccuracy: 0.3363 trainAccuracy: 0.9098 delta: -0.0176
Training:  15%|â–ˆâ–Œ        | 30/200 [12:56<1:12:39, 25.64s/it]epoch: 30 validateAccuracy: 0.3382 trainAccuracy: 0.9235 delta: -0.0157
Training:  16%|â–ˆâ–Œ        | 31/200 [13:22<1:12:20, 25.68s/it]epoch: 31 validateAccuracy: 0.3186 trainAccuracy: 0.9245 delta: -0.0353
Training:  16%|â–ˆâ–Œ        | 32/200 [13:48<1:12:25, 25.86s/it]epoch: 32 validateAccuracy: 0.3431 trainAccuracy: 0.9137 delta: -0.0108
Training:  16%|â–ˆâ–‹        | 33/200 [14:14<1:11:59, 25.86s/it]epoch: 33 validateAccuracy: 0.3353 trainAccuracy: 0.9304 delta: -0.0186
Training:  17%|â–ˆâ–‹        | 34/200 [14:40<1:11:18, 25.78s/it]epoch: 34 validateAccuracy: 0.3559 trainAccuracy: 0.9539 delta: 0.002
Training:  18%|â–ˆâ–Š        | 35/200 [15:08<1:13:19, 26.66s/it]epoch: 35 validateAccuracy: 0.3461 trainAccuracy: 0.9657 delta: -0.0098
Training:  18%|â–ˆâ–Š        | 36/200 [15:34<1:11:48, 26.27s/it]epoch: 36 validateAccuracy: 0.35 trainAccuracy: 0.9706 delta: -0.0059
Training:  18%|â–ˆâ–Š        | 37/200 [16:00<1:11:10, 26.20s/it]epoch: 37 validateAccuracy: 0.3559 trainAccuracy: 0.9745 delta: 0.0
Training:  19%|â–ˆâ–‰        | 38/200 [16:26<1:10:29, 26.11s/it]epoch: 38 validateAccuracy: 0.3588 trainAccuracy: 0.9784 delta: 0.0029
Training:  20%|â–ˆâ–‰        | 39/200 [16:54<1:11:55, 26.80s/it]epoch: 39 validateAccuracy: 0.3618 trainAccuracy: 0.9863 delta: 0.003
Training:  20%|â–ˆâ–ˆ        | 40/200 [17:23<1:13:09, 27.44s/it]epoch: 40 validateAccuracy: 0.3637 trainAccuracy: 0.998 delta: 0.0019
Training:  20%|â–ˆâ–ˆ        | 41/200 [17:52<1:13:49, 27.86s/it]epoch: 41 validateAccuracy: 0.3657 trainAccuracy: 0.9971 delta: 0.002
Training:  21%|â–ˆâ–ˆ        | 42/200 [18:21<1:14:27, 28.27s/it]epoch: 42 validateAccuracy: 0.3716 trainAccuracy: 0.998 delta: 0.0059
Training:  22%|â–ˆâ–ˆâ–       | 43/200 [18:50<1:14:34, 28.50s/it]epoch: 43 validateAccuracy: 0.3657 trainAccuracy: 0.998 delta: -0.0059
Training:  22%|â–ˆâ–ˆâ–       | 44/200 [19:16<1:11:47, 27.61s/it]epoch: 44 validateAccuracy: 0.3696 trainAccuracy: 0.9971 delta: -0.002
Training:  22%|â–ˆâ–ˆâ–Ž       | 45/200 [19:41<1:09:50, 27.04s/it]epoch: 45 validateAccuracy: 0.3696 trainAccuracy: 1.0 delta: -0.002
Training:  23%|â–ˆâ–ˆâ–Ž       | 46/200 [20:08<1:08:51, 26.83s/it]epoch: 46 validateAccuracy: 0.3667 trainAccuracy: 1.0 delta: -0.0049
Training:  24%|â–ˆâ–ˆâ–Ž       | 47/200 [20:33<1:07:34, 26.50s/it]epoch: 47 validateAccuracy: 0.3725 trainAccuracy: 0.998 delta: 0.0009
Training:  24%|â–ˆâ–ˆâ–       | 48/200 [21:03<1:09:08, 27.29s/it]epoch: 48 validateAccuracy: 0.3696 trainAccuracy: 0.999 delta: -0.0029
Training:  24%|â–ˆâ–ˆâ–       | 49/200 [21:28<1:07:22, 26.77s/it]epoch: 49 validateAccuracy: 0.3667 trainAccuracy: 0.999 delta: -0.0058
Training:  25%|â–ˆâ–ˆâ–Œ       | 50/200 [21:54<1:06:09, 26.46s/it]epoch: 50 validateAccuracy: 0.3696 trainAccuracy: 0.999 delta: -0.0029
Training:  26%|â–ˆâ–ˆâ–Œ       | 51/200 [22:19<1:04:42, 26.06s/it]epoch: 51 validateAccuracy: 0.3716 trainAccuracy: 0.998 delta: -0.0009
Training:  26%|â–ˆâ–ˆâ–Œ       | 52/200 [22:45<1:03:55, 25.91s/it]epoch: 52 validateAccuracy: 0.3765 trainAccuracy: 0.999 delta: 0.004
Training:  26%|â–ˆâ–ˆâ–‹       | 53/200 [23:14<1:05:49, 26.87s/it]epoch: 53 validateAccuracy: 0.3725 trainAccuracy: 1.0 delta: -0.004
Training:  27%|â–ˆâ–ˆâ–‹       | 54/200 [23:39<1:04:20, 26.44s/it]epoch: 54 validateAccuracy: 0.3676 trainAccuracy: 0.999 delta: -0.0089
Training:  28%|â–ˆâ–ˆâ–Š       | 55/200 [24:05<1:03:15, 26.18s/it]epoch: 55 validateAccuracy: 0.3706 trainAccuracy: 0.9971 delta: -0.0059
Training:  28%|â–ˆâ–ˆâ–Š       | 56/200 [24:30<1:02:16, 25.95s/it]epoch: 56 validateAccuracy: 0.3627 trainAccuracy: 0.998 delta: -0.0138
Training:  28%|â–ˆâ–ˆâ–Š       | 57/200 [24:56<1:01:31, 25.82s/it]epoch: 57 validateAccuracy: 0.35 trainAccuracy: 0.9843 delta: -0.0265
Training:  29%|â–ˆâ–ˆâ–‰       | 58/200 [25:21<1:00:38, 25.62s/it]epoch: 58 validateAccuracy: 0.35 trainAccuracy: 0.9618 delta: -0.0265
Training:  30%|â–ˆâ–ˆâ–‰       | 59/200 [25:46<1:00:11, 25.62s/it]epoch: 59 validateAccuracy: 0.35 trainAccuracy: 0.9608 delta: -0.0265
Training:  30%|â–ˆâ–ˆâ–ˆ       | 60/200 [26:12<59:50, 25.64s/it]  epoch: 60 validateAccuracy: 0.3471 trainAccuracy: 0.9755 delta: -0.0294
Training:  30%|â–ˆâ–ˆâ–ˆ       | 61/200 [26:38<59:50, 25.83s/it]epoch: 61 validateAccuracy: 0.3343 trainAccuracy: 0.9529 delta: -0.0422
Training:  31%|â–ˆâ–ˆâ–ˆ       | 62/200 [27:05<59:38, 25.93s/it]epoch: 62 validateAccuracy: 0.3392 trainAccuracy: 0.9137 delta: -0.0373
Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [27:30<59:01, 25.85s/it]epoch: 63 validateAccuracy: 0.3324 trainAccuracy: 0.9324 delta: -0.0441
Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [27:56<58:45, 25.93s/it]epoch: 64 validateAccuracy: 0.3539 trainAccuracy: 0.948 delta: -0.0226
Training:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [28:22<58:23, 25.95s/it]epoch: 65 validateAccuracy: 0.3471 trainAccuracy: 0.9676 delta: -0.0294
Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [28:48<57:33, 25.77s/it]epoch: 66 validateAccuracy: 0.3549 trainAccuracy: 0.9765 delta: -0.0216
Training:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [29:13<57:01, 25.73s/it]epoch: 67 validateAccuracy: 0.3608 trainAccuracy: 0.9971 delta: -0.0157
Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [29:38<55:53, 25.40s/it]epoch: 68 validateAccuracy: 0.3647 trainAccuracy: 0.999 delta: -0.0118
Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [30:03<54:59, 25.19s/it]epoch: 69 validateAccuracy: 0.3667 trainAccuracy: 0.999 delta: -0.0098
Training:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [30:28<54:35, 25.20s/it]epoch: 70 validateAccuracy: 0.3725 trainAccuracy: 0.999 delta: -0.004
Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [30:54<54:42, 25.45s/it]epoch: 71 validateAccuracy: 0.3716 trainAccuracy: 0.999 delta: -0.0049
Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [31:19<54:15, 25.43s/it]epoch: 72 validateAccuracy: 0.3745 trainAccuracy: 0.999 delta: -0.002
Training:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [31:44<53:37, 25.33s/it]epoch: 73 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.002
Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [32:10<53:19, 25.40s/it]epoch: 74 validateAccuracy: 0.3725 trainAccuracy: 0.999 delta: -0.004
Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [32:35<52:44, 25.32s/it]epoch: 75 validateAccuracy: 0.3725 trainAccuracy: 1.0 delta: -0.004
Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [33:00<52:19, 25.32s/it]epoch: 76 validateAccuracy: 0.3755 trainAccuracy: 1.0 delta: -0.001
Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [33:26<52:02, 25.39s/it]epoch: 77 validateAccuracy: 0.3765 trainAccuracy: 1.0 delta: 0.0
Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [33:52<51:45, 25.46s/it]epoch: 78 validateAccuracy: 0.3716 trainAccuracy: 1.0 delta: -0.0049
Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [34:17<51:07, 25.36s/it]epoch: 79 validateAccuracy: 0.3716 trainAccuracy: 1.0 delta: -0.0049
Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [34:42<50:53, 25.45s/it]epoch: 80 validateAccuracy: 0.3775 trainAccuracy: 1.0 delta: 0.001
Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [35:11<52:19, 26.39s/it]epoch: 81 validateAccuracy: 0.3725 trainAccuracy: 0.999 delta: -0.005
Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [35:37<51:29, 26.18s/it]epoch: 82 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.003
Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [36:02<50:26, 25.87s/it]epoch: 83 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.003
Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [36:27<49:33, 25.63s/it]epoch: 84 validateAccuracy: 0.3657 trainAccuracy: 1.0 delta: -0.0118
Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [36:53<49:11, 25.66s/it]epoch: 85 validateAccuracy: 0.3765 trainAccuracy: 1.0 delta: -0.001
Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [37:17<48:20, 25.44s/it]epoch: 86 validateAccuracy: 0.3755 trainAccuracy: 1.0 delta: -0.002
Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [37:43<47:56, 25.46s/it]epoch: 87 validateAccuracy: 0.3814 trainAccuracy: 1.0 delta: 0.0039
Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [38:12<49:30, 26.52s/it]epoch: 88 validateAccuracy: 0.3745 trainAccuracy: 0.999 delta: -0.0069
Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [38:38<48:34, 26.26s/it]epoch: 89 validateAccuracy: 0.3775 trainAccuracy: 0.998 delta: -0.0039
Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [39:03<47:46, 26.06s/it]epoch: 90 validateAccuracy: 0.3618 trainAccuracy: 0.9961 delta: -0.0196
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [39:29<46:56, 25.84s/it]epoch: 91 validateAccuracy: 0.3559 trainAccuracy: 0.9843 delta: -0.0255
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [39:49<43:32, 24.19s/it]epoch: 92 validateAccuracy: 0.35 trainAccuracy: 0.9647 delta: -0.0314
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [40:09<40:57, 22.96s/it]epoch: 93 validateAccuracy: 0.3412 trainAccuracy: 0.952 delta: -0.0402
Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [40:29<39:09, 22.16s/it]epoch: 94 validateAccuracy: 0.348 trainAccuracy: 0.9559 delta: -0.0334
Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [40:49<37:43, 21.56s/it]epoch: 95 validateAccuracy: 0.3471 trainAccuracy: 0.9549 delta: -0.0343
Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [41:10<36:47, 21.22s/it]epoch: 96 validateAccuracy: 0.3588 trainAccuracy: 0.9608 delta: -0.0226
Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [41:30<36:04, 21.01s/it]epoch: 97 validateAccuracy: 0.3284 trainAccuracy: 0.9775 delta: -0.053
Training:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [41:51<35:25, 20.84s/it]epoch: 98 validateAccuracy: 0.3549 trainAccuracy: 0.9912 delta: -0.0265
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [42:11<34:48, 20.67s/it]epoch: 99 validateAccuracy: 0.3578 trainAccuracy: 0.9971 delta: -0.0236
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [42:32<34:20, 20.60s/it]epoch: 100 validateAccuracy: 0.3647 trainAccuracy: 0.999 delta: -0.0167
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [42:52<34:05, 20.66s/it]epoch: 101 validateAccuracy: 0.3735 trainAccuracy: 1.0 delta: -0.0079
Training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [43:13<33:37, 20.58s/it]epoch: 102 validateAccuracy: 0.3755 trainAccuracy: 1.0 delta: -0.0059
Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [43:33<33:07, 20.49s/it]epoch: 103 validateAccuracy: 0.3755 trainAccuracy: 1.0 delta: -0.0059
Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [43:53<32:41, 20.44s/it]epoch: 104 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.0069
Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [44:14<32:20, 20.43s/it]epoch: 105 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.0069
Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [44:34<31:55, 20.37s/it]epoch: 106 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.0069
Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [44:54<31:38, 20.41s/it]epoch: 107 validateAccuracy: 0.3745 trainAccuracy: 1.0 delta: -0.0069
Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [45:15<31:19, 20.43s/it]epoch: 108 validateAccuracy: 0.3765 trainAccuracy: 1.0 delta: -0.0049
Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [45:36<31:09, 20.55s/it]epoch: 109 validateAccuracy: 0.3775 trainAccuracy: 1.0 delta: -0.0039
Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [45:56<30:42, 20.47s/it]epoch: 110 validateAccuracy: 0.3775 trainAccuracy: 1.0 delta: -0.0039
Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [46:17<30:28, 20.55s/it]epoch: 111 validateAccuracy: 0.3804 trainAccuracy: 1.0 delta: -0.001
Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [46:37<30:08, 20.55s/it]epoch: 112 validateAccuracy: 0.3794 trainAccuracy: 1.0 delta: -0.002
Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [46:58<29:43, 20.50s/it]epoch: 113 validateAccuracy: 0.3814 trainAccuracy: 1.0 delta: 0.0
Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [47:18<29:09, 20.34s/it]epoch: 114 validateAccuracy: 0.3784 trainAccuracy: 1.0 delta: -0.003
Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [47:38<28:46, 20.31s/it]epoch: 115 validateAccuracy: 0.3784 trainAccuracy: 1.0 delta: -0.003
Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [47:58<28:23, 20.28s/it]epoch: 116 validateAccuracy: 0.3755 trainAccuracy: 1.0 delta: -0.0059
Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [48:18<28:03, 20.29s/it]epoch: 117 validateAccuracy: 0.3725 trainAccuracy: 0.998 delta: -0.0089
Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [48:38<27:35, 20.19s/it]epoch: 118 validateAccuracy: 0.3716 trainAccuracy: 0.9971 delta: -0.0098
Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [48:59<27:14, 20.18s/it]epoch: 119 validateAccuracy: 0.3637 trainAccuracy: 0.9931 delta: -0.0177
Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [49:19<27:01, 20.27s/it]epoch: 120 validateAccuracy: 0.3559 trainAccuracy: 0.9853 delta: -0.0255
Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [49:39<26:32, 20.16s/it]epoch: 121 validateAccuracy: 0.3422 trainAccuracy: 0.9549 delta: -0.0392
Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [49:59<26:10, 20.14s/it]epoch: 122 validateAccuracy: 0.3549 trainAccuracy: 0.9578 delta: -0.0265
Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [50:19<25:58, 20.24s/it]epoch: 123 validateAccuracy: 0.348 trainAccuracy: 0.9559 delta: -0.0334
Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [50:40<25:42, 20.29s/it]epoch: 124 validateAccuracy: 0.3324 trainAccuracy: 0.9657 delta: -0.049
Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [51:00<25:16, 20.23s/it]epoch: 125 validateAccuracy: 0.348 trainAccuracy: 0.9706 delta: -0.0334
Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [51:18<23:59, 19.46s/it]epoch: 126 validateAccuracy: 0.3402 trainAccuracy: 0.9618 delta: -0.0412
Training:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [51:35<23:01, 18.93s/it]epoch: 127 validateAccuracy: 0.349 trainAccuracy: 0.9745 delta: -0.0324
Training:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [51:53<22:12, 18.50s/it]epoch: 128 validateAccuracy: 0.3598 trainAccuracy: 0.9755 delta: -0.0216
Training:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [52:10<21:32, 18.21s/it]epoch: 129 validateAccuracy: 0.3588 trainAccuracy: 0.9873 delta: -0.0226
Training:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [52:28<20:59, 18.00s/it]epoch: 130 validateAccuracy: 0.3647 trainAccuracy: 0.9931 delta: -0.0167
Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [52:45<20:31, 17.85s/it]epoch: 131 validateAccuracy: 0.3706 trainAccuracy: 0.999 delta: -0.0108
Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [53:03<20:05, 17.73s/it]epoch: 132 validateAccuracy: 0.3716 trainAccuracy: 1.0 delta: -0.0098
Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [53:20<19:44, 17.69s/it]epoch: 133 validateAccuracy: 0.3676 trainAccuracy: 1.0 delta: -0.0138
Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [53:38<19:22, 17.62s/it]epoch: 134 validateAccuracy: 0.3676 trainAccuracy: 0.999 delta: -0.0138
Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [53:55<19:02, 17.58s/it]epoch: 135 validateAccuracy: 0.3618 trainAccuracy: 1.0 delta: -0.0196
Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [54:13<18:43, 17.56s/it]epoch: 136 validateAccuracy: 0.3637 trainAccuracy: 1.0 delta: -0.0177
Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [54:30<18:25, 17.55s/it]epoch: 137 validateAccuracy: 0.3647 trainAccuracy: 1.0 delta: -0.0167
Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [54:48<25:12, 24.00s/it]
Traceback (most recent call last):
  File "main.py", line 287, in <module>
    # train(model=vitModel,modelName="ViT",learningRate=5e-5,epochs=200,etaMin=1e-5,imageSize=224,batchSize=64,savedName="0_2.pkl",)
  File "main.py", line 278, in train
    testAccuracy=get_test_data_set_accuracy(model,imageSize)
  File "main.py", line 198, in get_test_data_set_accuracy
    trainDataSet, validateDataSet, testDataSet=construct_data_loader(imageSize=imageSize)
TypeError: construct_data_loader() missing 1 required positional argument: 'batchSize'
